{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from importlib import reload \n",
    "\n",
    "#add simulator to a path\n",
    "sys.path.append('Simulator/')\n",
    "\n",
    "\n",
    "import estimation_methods as em\n",
    "import noise_models as nm\n",
    "import utils as utl  \n",
    "import simulation as sm\n",
    "import analyser as anl\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2   \n",
    "\n",
    "\n",
    "\n",
    "    def estimate(self, om, mu, std, t, rng_shot = np.random.default_rng()):\n",
    "        x = rng_shot.binomial(1, 1/2+1/2*np.cos(2*np.pi*om*t))\n",
    "        x = 2*x-1\n",
    "        mu, std = update_p(x, mu, std, t) \n",
    "        return mu, std/mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def likelihood(x, om, tau, dom):\n",
    "    return 1/2 + x/2*np.cos(dom * tau + om * tau)\n",
    "\n",
    "def normal_dist(x, mu, sigma):\n",
    "    return np.exp(-1/2 * (x - mu)**2 / sigma**2)/np.sum(np.exp(-1/2 * (x - mu)**2 / sigma**2))\n",
    "\n",
    "def prob_update(x, mu, std):\n",
    "    \n",
    "    t = 2*np.pi * t\n",
    "    denom = 1 + x*np.cos(mu*t)*np.exp(-std**2*t**2/2)\n",
    "    m1 = (mu+x*(mu*np.cos(mu*t)-np.sin(mu*t)*std**2*t\n",
    "             )*np.exp(-std**2*t**2/2))/denom\n",
    "    m20 = std**2+mu**2\n",
    "    m2 = (m20+x*((mu**2+std**2-std**4*t**2)*np.cos(mu*t\n",
    "          )-2*np.sin(mu*t)*std**2*t*mu\n",
    "             )*np.exp(-std**2*t**2/2))/denom\n",
    "    return m1, np.sqrt(m2-m1**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(noise,estimation_method):\n",
    "    estimation_method.reset_pdf(SHOT_TIME, noise)\n",
    "    for k in range(estimation_method.N):\n",
    "\n",
    "        a = simulator.run_single_realisation([estimation_method], noise)\n",
    "\n",
    " \n",
    "    return estimation_method.get_avg()\n",
    "\n",
    "def get_bit(omega_est, noise, phi):\n",
    "    t = phi/omega_est*1e3/2/np.pi\n",
    "    prob = (1 + np.cos(2*np.pi*noise.x*t/1e3))/2\n",
    "\n",
    "    noise.update(SHOT_TIME)\n",
    "    return np.random.choice([1,0], p = [prob, 1-prob])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "initial_mu = 0  #initial average of dom\n",
    "SHOTS = 20 #numver of shots\n",
    "#initialization\n",
    "dom0 = -7   #system frequency detuning to be estimated \n",
    "df0 = 2    #controlled detuning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "dom = [dom0]\n",
    "dfs = []\n",
    "taus = []\n",
    "n = 4   #how wide is the filter \n",
    "\n",
    "def get_df(sig, mu,n):\n",
    "    # such that (mu+om)*tau = pi/2, in case of which p(0) = p(1)\n",
    "    return n*sig/2-mu\n",
    "\n",
    "def get_tau(sig, n):\n",
    "    # such that sig*tau = pi/n, and width of the filter is sig\n",
    "    return np.pi/n/sig\n",
    "\n",
    "print(n)\n",
    "dfs.append(get_df(initial_sig,initial_mu,n)) \n",
    "taus.append(get_tau(initial_sig,n))\n",
    "\n",
    "sigs = [initial_sig]\n",
    "mus = [initial_mu]\n",
    "\n",
    "prob_exact_reg = [normal_dist(dom_grid, initial_mu, initial_sig)]\n",
    "prob_approx_reg = [normal_dist(dom_grid, initial_mu, initial_sig)]\n",
    "\n",
    "for s in range(SHOTS):\n",
    "    p = likelihood(1,dfs[-1],taus[-1],dom[-1]) #probability p = p(1), p(0) = 1-p\n",
    "    x = 2 * np.random.choice(2, p = (1-p,p))-1    #measureement 1 or -1\n",
    "\n",
    "    #update the probability distribution\n",
    "    prob_exact, mu, sigma = prob_update(x, dfs[-1], taus[-1], dom_grid, mus[-1], sigs[-1])     \n",
    "\n",
    "    #get next detuning and evolution time:\n",
    "    dfs.append(get_df(sigma, mu, n))  #controlled detuning \n",
    "    taus.append(get_tau(sigma,n)) #evolution time\n",
    "\n",
    "    #save results\n",
    "    prob_exact_reg.append(prob_exact)\n",
    "    prob_gaussian = normal_dist(dom_grid, mu, sigma) #project it into gaussian\n",
    "    prob_approx_reg.append(prob_gaussian)\n",
    "    sigs.append(sigma)\n",
    "    mus.append(mu)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BITS_PER_REPETITIONS = 1\n",
    "REPETITIONS = 2000\n",
    "phis = np.linspace(0, 5*np.pi, 51)\n",
    "bits_est = np.zeros((REPETITIONS, len(phis),BITS_PER_REPETITIONS))\n",
    "bits_no_est = np.zeros((REPETITIONS,len(phis),BITS_PER_REPETITIONS))\n",
    "SHOT_TIME = 1e4\n",
    "N_SHOTS = 5\n",
    "QUBIT_FREQ = 2 #MHz\n",
    "\n",
    "\n",
    "total_time = (N_SHOTS + BITS_PER_REPETITIONS)*REPETITIONS * SHOT_TIME\n",
    "ommin = 1/1e8\n",
    "ommax = 1/1e3\n",
    "N_TELEGRAPHS = 15\n",
    "noise = nm.Over_f_noise(n_fluctuators = N_TELEGRAPHS, S1  = 2,\n",
    "                        couplings_dispersion = 0.2, \n",
    "                        ommax = ommax , \n",
    "                        ommin = ommin, \n",
    "                        om0 = QUBIT_FREQ,\n",
    "                        fluctuator_class = nm.OrnsteinUhlenbeck)\n",
    "\n",
    "\n",
    "dom = []\n",
    "filtered = []\n",
    "N = 5\n",
    "mov_avg = 0\n",
    "est_raw = []\n",
    "xis = []\n",
    "for n in range(REPETITIONS):\n",
    "    if n%100==0:\n",
    "        print(n/REPETITIONS)\n",
    "    for pn,phi in enumerate(phis):\n",
    "\n",
    "        estimate()\n",
    "        xis.append(noise.x)\n",
    "\n",
    "        if len(est_raw)<N:\n",
    "            mov_avg = np.average(est_raw)\n",
    "        else:\n",
    "            mov_avg = mov_avg + (est_raw[-1] - est_raw[-N])/N\n",
    "            \n",
    "        filtered.append(mov_avg)\n",
    "        for b in range(BITS_PER_REPETITIONS):\n",
    "            bits_no_est[n,pn,b] = get_bit(10, noise, phi)\n",
    "            bits_est[n,pn, b] = get_bit(filtered[-1], noise, phi)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate(noise,estimation_method):\n",
    "    estimation_method.reset_pdf(SHOT_TIME, noise)\n",
    "    for k in range(estimation_method.N):\n",
    "\n",
    "        a = simulator.run_single_realisation([estimation_method], noise)\n",
    "\n",
    " \n",
    "    return estimation_method.get_avg()\n",
    "\n",
    "def get_bit(omega_est, noise, phi):\n",
    "    t = phi/omega_est*1e3/2/np.pi\n",
    "    prob = (1 + np.cos(2*np.pi*noise.x*t/1e3))/2\n",
    "\n",
    "    noise.update(SHOT_TIME)\n",
    "    return np.random.choice([1,0], p = [prob, 1-prob])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
